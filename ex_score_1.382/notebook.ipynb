{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27a02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9235366",
   "metadata": {},
   "source": [
    "# Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf01c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    '''\n",
    "    https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error\n",
    "    '''\n",
    "    smap = np.zeros(len(y_true))\n",
    "    \n",
    "    num = np.abs(y_true - y_pred)\n",
    "    dem = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    \n",
    "    pos_ind = (y_true!=0)|(y_pred!=0)\n",
    "    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n",
    "    \n",
    "    return 100*np.mean(smap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e35d0",
   "metadata": {},
   "source": [
    "# Prepare train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb42496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128535 18810 25080\n"
     ]
    }
   ],
   "source": [
    "# based on https://www.kaggle.com/code/vadimkamaev/score-1-382/notebook\n",
    "\n",
    "data_dir = '../data/'\n",
    "\n",
    "def get_train_test():    \n",
    "    # combine the original training set with the revealed data\n",
    "    train = pd.concat([\n",
    "        pd.read_csv(f'{data_dir}/train.csv'), \n",
    "        pd.read_csv(f'{data_dir}/revealed_test.csv')\n",
    "    ]).sort_values(by=['cfips', 'first_day_of_month']).reset_index(0, drop=True)\n",
    "    train['is_test'] = 0\n",
    "\n",
    "    # drop the test data that has already been revealed\n",
    "    test = pd.read_csv(f'{data_dir}/test.csv')\n",
    "    drop_index = (test.first_day_of_month == '2022-11-01') | (test.first_day_of_month == '2022-12-01')\n",
    "    test = test.loc[~drop_index, :]\n",
    "    test['is_test'] = 1\n",
    "    \n",
    "    sub = pd.read_csv(f'{data_dir}/sample_submission.csv')\n",
    "    return train, test, sub\n",
    "\n",
    "train, test, sub = get_train_test()\n",
    "print(len(train), len(test), len(sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ba369",
   "metadata": {},
   "source": [
    "# Combine raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238712b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw(train, test):\n",
    "    raw = pd.concat([train, test]).sort_values(['cfips', 'row_id']).reset_index(0, drop=True)\n",
    "    raw['first_day_of_month'] = pd.to_datetime(raw[\"first_day_of_month\"])\n",
    "    raw['county'] = raw.groupby('cfips')['county'].ffill()\n",
    "    raw['state'] = raw.groupby('cfips')['state'].ffill()\n",
    "    raw['county_i'] = (raw['county'] + raw['state']).factorize()[0]\n",
    "    raw['state_i'] = raw['state'].factorize()[0]\n",
    "    raw['month_number'] = raw.groupby(['cfips'])['row_id'].cumcount()\n",
    "    raw['y'] = raw['microbusiness_density']\n",
    "    raw = raw.drop('microbusiness_density', axis=1)\n",
    "    features = ['state_i']    \n",
    "    return raw, features\n",
    "\n",
    "raw, features = get_raw(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf8355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# raw['scale'] = (raw['first_day_of_month'] - raw['first_day_of_month'].min()).dt.days\n",
    "# raw['scale'] = raw['scale'].factorize()[0]\n",
    "# raw\n",
    "# raw.groupby('cfips')['microbusiness_density'].shift(-1)/raw['microbusiness_density'] - 1\n",
    "# raw['lastactive'] = raw.groupby('cfips')['active'].transform('last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3142900",
   "metadata": {},
   "source": [
    "# Feature engineering: lag and rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95181a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag(raw, features, target='y', max_lag=8):\n",
    "    for lag in range(1, max_lag):\n",
    "        raw[f'{target}_lag_{lag}'] = raw.groupby('cfips')[target].shift(lag)\n",
    "        features.append(f'{target}_lag_{lag}')        \n",
    "        # raw[f'active_lag_{lag}'] = raw.groupby('cfips')['active'].diff(lag)        \n",
    "        # feats.append(f'active_lag_{lag}')        \n",
    "    return raw, features\n",
    "\n",
    "def add_rolling(raw, features, target='y', lags=[1]):\n",
    "    \n",
    "    def get_rolling(s, window):\n",
    "        return s.rolling(window, min_periods=1).sum()\n",
    "        \n",
    "    for lag in lags:\n",
    "        for window in [2, 4, 6, 8, 10]:\n",
    "            raw[f'{target}_roll_{window}_{lag}'] = raw.groupby('cfips')[f'{target}_lag_{lag}'].transform(get_rolling, window=window)\n",
    "            features.append(f'{target}_roll_{window}_{lag}')\n",
    "    return raw, features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e315843",
   "metadata": {},
   "source": [
    "# Feature engineering: internal and external census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8739078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_internal_census(raw, features):\n",
    "    census = pd.read_csv(f'{data_dir}/census_starter.csv')\n",
    "    census_cols = list(census.columns)\n",
    "    census_cols.remove('cfips')\n",
    "    raw = raw.merge(census, on='cfips', how='left')\n",
    "    features += census_columns\n",
    "    return raw, features\n",
    "\n",
    "def add_external_census(raw, features):\n",
    "    '''\n",
    "    data: https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/counties/totals/co-est2021-alldata.csv\n",
    "    schema: https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2020-2021/CO-EST2021-ALLDATA.pdf\n",
    "    '''\n",
    "    census = pd.read_csv(f'{data_dir}/co-est2021-alldata.csv', encoding='latin-1')\n",
    "    census['cfips'] = survey.STATE*1000 + survey.COUNTY\n",
    "    features += [\n",
    "        'SUMLEV',\n",
    "        'REGION',\n",
    "        'DIVISION',\n",
    "        'ESTIMATESBASE2020',\n",
    "        'POPESTIMATE2020',\n",
    "        'POPESTIMATE2021',\n",
    "        'NPOPCHG2020',\n",
    "        'NPOPCHG2021',\n",
    "        'BIRTHS2020',\n",
    "        'BIRTHS2021',\n",
    "        'DEATHS2020',\n",
    "        'DEATHS2021',\n",
    "        'NATURALCHG2020',\n",
    "        'NATURALCHG2021',\n",
    "        'INTERNATIONALMIG2020',\n",
    "        'INTERNATIONALMIG2021',\n",
    "        'DOMESTICMIG2020',\n",
    "        'DOMESTICMIG2021',\n",
    "        'NETMIG2020',\n",
    "        'NETMIG2021',\n",
    "        'RESIDUAL2020',\n",
    "        'RESIDUAL2021',\n",
    "        'GQESTIMATESBASE2020',\n",
    "        'GQESTIMATES2020',\n",
    "        'GQESTIMATES2021',\n",
    "        'RBIRTH2021',\n",
    "        'RDEATH2021',\n",
    "        'RNATURALCHG2021',\n",
    "        'RINTERNATIONALMIG2021',\n",
    "        'RDOMESTICMIG2021',\n",
    "        'RNETMIG2021'\n",
    "    ]\n",
    "    raw = raw.merge(survey, on='cfips', how='left')\n",
    "    return raw, features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eb8f9f",
   "metadata": {},
   "source": [
    "# Feature engineering: coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b2119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coords(raw, features):\n",
    "    '''\n",
    "    https://www.kaggle.com/datasets/alejopaullier/usa-counties-coordinates\n",
    "    '''\n",
    "    coords = pd.read_csv(f'{data_dir}/cfips_location.csv').drop('name', axis=1) \n",
    "    raw = raw.merge(coords, on='cfips')\n",
    "    features += ['lng', 'lat']\n",
    "    return raw, features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffef3fe",
   "metadata": {},
   "source": [
    "# Feature engineering: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83c6252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_i',\n",
       " 'y_lag_1',\n",
       " 'y_lag_2',\n",
       " 'y_lag_3',\n",
       " 'y_lag_4',\n",
       " 'y_lag_5',\n",
       " 'y_lag_6',\n",
       " 'y_lag_7']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw, features = add_lag(raw, features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce21421",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5534d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x21b09885fc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    from sklearn.ensemble import VotingRegressor\n",
    "    import lightgbm as lgb\n",
    "    import xgboost as xgb\n",
    "    import catboost as cat\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.impute import KNNImputer    \n",
    "\n",
    "    # we should decrease the num_iterations of catboost\n",
    "    cat_model = cat.CatBoostRegressor(\n",
    "        iterations=800,\n",
    "        loss_function=\"MAPE\",\n",
    "        verbose=0,\n",
    "        grow_policy='SymmetricTree',\n",
    "        learning_rate=0.035,\n",
    "        colsample_bylevel=0.8,\n",
    "        max_depth=5,\n",
    "        l2_leaf_reg=0.2,\n",
    "        # max_leaves = 17,\n",
    "        subsample=0.70,\n",
    "        max_bin=4096,\n",
    "    )\n",
    "    return cat_model\n",
    "\n",
    "get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a613bd8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "979b22dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "TS: 39\n",
      "Last Value SMAPE: 1.889206717018118\n",
      "SMAPE: 3.387869772778022\n",
      "SMAPE: 3.387869772778022\n",
      "Last Value SMAPE: 1.889206717018118\n"
     ]
    }
   ],
   "source": [
    "ACT_THR = 140\n",
    "MONTH_1 = 39\n",
    "MONTH_last = 40\n",
    "\n",
    "raw['ypred_last'] = np.nan\n",
    "raw['ypred'] = np.nan\n",
    "raw['k'] = 1.\n",
    "raw['y'].fillna(0, inplace = True)\n",
    "\n",
    "for TS in range(MONTH_1, MONTH_last): #40):\n",
    "    print(TS)   \n",
    "    model = get_model()            \n",
    "    train_idxs = (raw.is_test==0) & (raw.month_number  < TS) & (raw.month_number >= 1) # & (raw.lastactive>ACT_THR) \n",
    "    valid_idxs = (raw.is_test==0) & (raw.month_number == TS) \n",
    "    model.fit(\n",
    "        raw.loc[train_idxs, features],\n",
    "        # raw.loc[train_idxs, 'target'].clip(-0.0043, 0.0045),\n",
    "        raw.loc[train_idxs, 'y'],\n",
    "    )\n",
    "\n",
    "    ypred = model.predict(raw.loc[valid_indices, features])\n",
    "    raw.loc[valid_idxs, 'k'] = (ypred + 1)*raw.loc[valid_idxs,'y']\n",
    "    raw.loc[valid_idxs, 'yhat'] = ypred\n",
    "    \n",
    "\n",
    "    # Validate\n",
    "    ylast_dict = raw.loc[raw.month_number==TS, ['cfips', 'y']].set_index('cfips').to_dict()['y']\n",
    "    yhat_dict = raw.loc[raw.month_number==TS, ['cfips', 'yhat']].set_index('cfips').to_dict()['yhat']\n",
    "    df = raw.loc[raw.month_number == (TS+1), \n",
    "                 ['cfips', 'y', 'state', \n",
    "#                   'lastactive', \n",
    "                  'y_lag_1']].reset_index(drop=True)\n",
    "    df['yhat'] = df['cfips'].map(yhat_dict)\n",
    "    df['ylast'] = df['cfips'].map(ylast_dict)\n",
    "#     df.loc[df['lastval'].isnull(), 'lastval'] = df.loc[df['lastval'].isnull(), 'microbusiness_density']    \n",
    "    \n",
    "    # df.loc[df['lastactive']<=ACT_THR, 'pred'] = df.loc[df['lastactive']<=ACT_THR, 'lastval']\n",
    "        \n",
    "    raw.loc[raw.month_number==(TS+1), 'ypred'] = df['yhat'].values\n",
    "    raw.loc[raw.month_number==(TS+1), 'ypred_last'] = df['ylast'].values\n",
    "    \n",
    "    print(f'TS: {TS}')\n",
    "    print('Last Value SMAPE:', smape(df['y'], df['ylast']) )\n",
    "    print('SMAPE:', smape(df['y'], df['yhat']))\n",
    "\n",
    "ind = (raw.month_number > MONTH_1)&(raw.month_number <= MONTH_last)\n",
    "\n",
    "print( 'SMAPE:', smape( raw.loc[ind, 'y'],  raw.loc[ind, 'ypred'] ) )\n",
    "print( 'Last Value SMAPE:', smape( raw.loc[ind, 'y'],  raw.loc[ind, 'ypred_last'] ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
